---
title: Some Notes on the Cauchy Distribution
author: 'Joseph Rickert'
date: '2017-02-15'
categories: [Statistics, R Language]
tage: [Probability Distributions, R]
draft: no
---


<p>by Joseph Rickert</p>
<p>I have always been attracted to the capricious. So, it was no surprise that I fell for the <a href="https://en.wikipedia.org/wiki/Cauchy_distribution">Cauchy distribution</a> at first sight. I had never seen such unpredictability! You might say that every distribution has its moments of unpredictability, but the great charm of Cauchy is that it has no moments. (No finite moments, anyway.)</p>
<p>Before discussing why momentlessness (not being in the moment :) ) leads to unpredictability, let’s derive the Cauchy distribution. A common conceit for doing this is to consider a blindfolded archer trying to hit a target directly in front of him. He randomly shoots towards the wall at an angle <span class="math inline">\(\theta\)</span> that can sometimes be so large he shoots parallel to the wall!</p>
<p>Where on the wall is any given arrow likely to land? The following diagram maps out the situation. <img src="/post/2017-02-15-some-notes-on-the-cauchy-distribution_files/Archer.png" /></p>
<p>The archer is standing at the point (0, 0). The point on the wall directly in front of him is (x, 0), and the arrow will land at (x, y), (x, -y), or not at all. After changing to polar coordinates, a moments reflection will give you the equation <span class="math inline">\(y = xtan(\theta)\)</span>.</p>
<p>Assuming that theta is uniformly distributed on the interval <span class="math inline">\(I = (- \pi/2, \pi/2)\)</span>, a direct substitution into the equation for the CDF of the uniform distribution will yield the CDF for the Cauchy distribution.</p>
<p><span class="math display">\[P(Y \leq y) = P(xtan(\theta) \leq y) = P(\theta \leq arctan(y/x)) = arctan(y/x) / \pi + 1/2\]</span></p>
<p>Differentiating this gives the Cauchy density function: <span class="math display">\[f(y) = \frac{x}{\pi(x^{2} + y^{2})}\]</span> This looks tame, but a short argument showing that the <a href="https://www.youtube.com/watch?v=Q7n7EPacAu8">necessary integrals do not converge</a> demonstrates that neither the mean nor the variance exist. Hence, neither the Law of Large Numbers, nor the Central Limit Theorem apply. Taking lots of samples and computing averages doesn’t buy you anything. The averages just don’t settle down. This behavior is apparent in the following simulation that computes means of Cauchy samples for sample sizes of one to five thousand. The plots that show the same data at different scales dramatize the erratic behavior.</p>
<pre class="r"><code>set.seed(pi)
N &lt;- 5000
shots &lt;- 1:N
arrows &lt;- rcauchy(N)
means &lt;- cumsum(arrows) / shots
summary(means)</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
## -8.1130 -0.6115  1.1500 22.7800 71.0000 96.4300</code></pre>
<pre class="r"><code>plot(shots, arrows, pch = &quot;.&quot;, ylim = c(-10, 10))
points(shots, means, type = &quot;l&quot;, col = &quot;red&quot;)</code></pre>
<p><img src="/post/2017-02-15-some-notes-on-the-cauchy-distribution_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<pre class="r"><code>plot(shots, arrows, pch = &quot;.&quot;, ylim = c(-10, 100))
points(shots, means, type = &quot;l&quot;, col = &quot;red&quot;)</code></pre>
<p><img src="/post/2017-02-15-some-notes-on-the-cauchy-distribution_files/figure-html/unnamed-chunk-1-2.png" width="672" /></p>
<p>Not only don’t the samples converge, it is not that difficult to show that the distribution of the sample mean:</p>
<p><span class="math display">\[Y =\frac{Y_{1} + Y_{2} . . . + Y_{n} }{n}\]</span> of n independent Cauchy random variables has the same distribution as a single Cauchy random variable! The proof is straightforward. Let <span class="math inline">\(\phi(t)\)</span> be the characteristic function. Then<br />
<span class="math display">\[ \phi_{Y}(t) = [\phi_{Y1}(t)]^n= e^{-n|t|}\]</span> which is the characteristic function of nY.</p>
<p>The extreme values that dominate the Cauchy distribution make it the prototypical heavy-tailed distribution. Informally, a distribution is often described as having heavy or “fat” tails if the probability of events in the tails of the distribution are greater than what would be given by a Normal distribution. While there seems to be more than one formal definition of a [heavy-tailed distribution] (<a href="https://en.wikipedia.org/wiki/Heavy-tailed_distribution" class="uri">https://en.wikipedia.org/wiki/Heavy-tailed_distribution</a>), the following diagram, which compares the right tails of the Normal, Exponential and Cauchy distributions, gets the general idea across.</p>
<pre class="r"><code># Plot right tails of distributions
low &lt;- 0; high &lt;- 6
curve(dnorm,from = low, to = high, ylim = c(0, .05), col = &quot;blue&quot;, ylab = &quot; &quot;, add = FALSE) 
curve(dcauchy,from = low, to = high, col = &quot;red&quot;, add = TRUE) 
curve(dexp,from = low, to = high, col = &quot;black&quot;, add = TRUE) 

legend(0,0.03, c(&quot;Normal&quot;, &quot;Exp&quot;, &quot;Cauchy&quot;), 
  lty=c(1,1,1), # symbols (lines)
  lwd=c(2,2,2), col=c(&quot;blue&quot;, &quot;black&quot;, &quot;red&quot;))</code></pre>
<p><img src="/post/2017-02-15-some-notes-on-the-cauchy-distribution_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>As exotic as the Cauchy distribution may seem, it is not all that difficult to come face-to-face with the Cauchy Distribution in every-day modeling work. A student t distribution with one degree of freedom is Cauchy, as is the <a href="http://www.math.wm.edu/~leemis/chart/UDR/PDFs/StandardnormalStandardcauchy.pdf">ratio of two independent standard normal random variables</a>.</p>
<p>Additionally, the Cauchy distribution, also called the Breit-Wigner, or Lorentz distribution, has applications in <a href="http://www.hep.phy.cam.ac.uk/~thomson/lectures/partIIIparticles/Handout14_2009.pdf">particle physics</a>, <a href="https://en.wikipedia.org/wiki/Spectral_line_shape#Line_shape_functions">spectroscopy</a>, <a href="http://www.scienpress.com/Upload/TMA/Vol%201_1_7.pdf">finance</a>, and medicine. In his 2006 <a href="file:///Users/JBRickert/Downloads/v16i04.pdf">JSS paper</a>, Geroge Marsaglia elaborates on early work he did on transforming the ratio of two jointly Normal random variables into something tractable. The original problem arose from an attempt to estimate the intercept in a linear model giving the life span of red blood cells.</p>
<p>The real fun, and maybe the real world, seems to happen when things are not normal.</p>
<div id="further-reading" class="section level3">
<h3>Further Reading</h3>
<ul>
<li><p>The <a href="https://www.crcpress.com/Introduction-to-Probability-with-R/Baclawski/p/book/9781420065213">Introduction to Probability with R</a> by Kenneth Baclawski, based on a course he developed with Gian-Carlo Rota, is a delightful introduction to probability theory. The idea of plotting the sample means above comes from Section 5.7 of this book.</p></li>
<li><p>For some good reading on heavy-tailed distributions, have a look at the extended presentation on the <a href="http://users.cms.caltech.edu/~adamw/papers/2013-SIGMETRICS-heavytails.pdf">Fundamentals of Heavy Tails</a> by Nair et al.; <a href="http://www.springer.com/cda/content/document/cda_downloaddocument/9781461487876-c1.pdf?SGWID=0-0-45-1443310-p175370772">Chapter 2</a> of <a href="http://www.springer.com/us/book/9781461487876">The Statistical Analysis of Financial Data in R</a>; and <a href="http://www.springer.com/cda/content/document/cda_downloaddocument/9781461471004-c1.pdf?SGWID=0-0-45-1395304-p175250259">Chapter 2</a> of <a href="http://www.springer.com/us/book/9781461471004#otherversion=9781489988324">An Introduction to Heavy-Tailed and Sucexponential Distributions</a> by Foss et al.</p></li>
<li><p>For a sophisticated but accessible look at general Stable Distributions, have a look at this <a href="https://en.wikipedia.org/wiki/Heavy-tailed_distribution">recent paper</a> on Stable Distributions, by John Nolan.</p></li>
</ul>
</div>
